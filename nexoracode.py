BOT_TOKEN = "8140893616:AAHWFDGPp2Tx7gt43oO3tl4-YpzhbukOVSQ"

# –°–æ–∑–¥–∞–µ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –±–æ—Ç–∞
application = Application.builder().token(BOT_TOKEN).build()

# –ü—Ä–∏–º–µ—Ä —Å–ª–æ–≤–∞—Ä—è —ç–º–æ—Ü–∏–π –∂–∏–≤–æ—Ç–Ω—ã—Ö –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
emotions_dict = {
    0: "–°–ø–æ–∫–æ–π–Ω–æ–µ",
    1: "–ê–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–µ",
    2: "–ò—Å–ø—É–≥–∞–Ω–Ω–æ–µ",
    3: "–ò–≥—Ä–æ–≤–æ–µ",
    4: "–†–∞–∑–¥—Ä–∞–∂–µ–Ω–Ω–æ–µ",
}

def recognize_animal_and_emotion(audio_bytes):
    speech, sr = librosa.load(io.BytesIO(audio_bytes), sr=16000)
    inputs = feature_extractor(speech, return_tensors="pt", sampling_rate=16000)
    with torch.no_grad():
        logits = model(**inputs).logits
        probs = torch.softmax(logits, dim=-1)
        predicted_id = torch.argmax(logits, dim=-1).item()
        confidence = probs.max().item()
    label = model.config.id2label[predicted_id]

    # –ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è —ç–º–æ—Ü–∏–π: —Å–ª—É—á–∞–π–Ω–∞—è —ç–º–æ—Ü–∏—è –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞
    emotion_id = np.random.choice(list(emotions_dict.keys()))
    emotion_label = emotions_dict.get(emotion_id, "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")

    top3 = torch.topk(probs, 3)
    result = f"üêò {label.upper()} üéØ –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.1%}\n\nüìã –¢–û–ü-3:\n"
    for i, (prob, idx) in enumerate(zip(top3.values[0], top3.indices[0])):
        result += f"{i+1}. {model.config.id2label[idx.item()]}: {prob:.1%}\n"

    result += f"\nüí¨ –≠–º–æ—Ü–∏—è: {emotion_label}"
    return result

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("üê± –û—Ç–ø—Ä–∞–≤—å –≥–æ–ª–æ—Å–æ–≤–æ–µ –∏–ª–∏ wav-—Ñ–∞–π–ª, —è –æ–ø—Ä–µ–¥–µ–ª—é –∂–∏–≤–æ—Ç–Ω–æ–µ –∏ —ç–º–æ—Ü–∏—é!", parse_mode="Markdown")

async def handle_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("üîÑ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –∑–≤—É–∫...")
    voice = await update.voice.get_file()
    audio_bytes = await voice.download_as_bytearray()
    result = recognize_animal_and_emotion(audio_bytes)
    await update.message.reply_text(result, parse_mode="Markdown")

async def handle_audio(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("üîÑ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –∑–≤—É–∫...")
    audio = await update.message.audio.get_file()
    audio_bytes = await audio.download_as_bytearray()
    result = recognize_animal_and_emotion(audio_bytes)
    await update.message.reply_text(result, parse_mode="Markdown")

application.add_handler(CommandHandler("start", start))
application.add_handler(MessageHandler(filters.VOICE, handle_voice))
application.add_handler(MessageHandler(filters.AUDIO, handle_audio))

async def run():
    await application.initialize()
    await application.start()
    print("üöÄ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω –∏ –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ.")
    await asyncio.Event().wait()

asyncio.get_event_loop().run_until_complete(run())        #–±–æ—Ç –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è Dauren_bot
